import streamlit as st
from transformers import pipeline, Pipeline, AutoTokenizer, AutoModelForSequenceClassification
import os
import time
from PIL import Image
import imagehash
import io
import math
import json
from transformers import AutoImageProcessor, AutoModelForImageClassification
from PIL import Image
import torch


MODEL_CV = "prithivMLmods/Deep-Fake-Detector-v2-Model"


image_processor = AutoImageProcessor.from_pretrained(MODEL_CV)
model_cv = AutoModelForImageClassification.from_pretrained(MODEL_CV)

def analyze_image(image_path):
    image = Image.open(image_path)
    inputs = image_processor(image, return_tensors="pt")
    with torch.no_grad():
        outputs = model_cv(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        confidence = probs.max().item()
        label = model_cv.config.id2label[probs.argmax().item()]
    return {"label": label, "confidence": confidence}

hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

MODEL_NAME =  "sereotubu/fake-news-detector-isot"
REPORTS_DIR = "reports"
IMAGE_DB_DIR = "image_db"  

SENSATIONAL_WORDS = {
    "shocking","unbelievable","breaking","exclusive","must-see","miracle",
    "secret","you won't believe","this will change","revealed","exposed"
}


W_MODEL = 0.5
W_TEXTHEUR = 0.4
W_MEDIA = 0.1



@st.cache_resource(show_spinner=False)
def load_model():
    """Load transformers pipeline once."""
    try:
        clf = pipeline("text-classification", model=MODEL_NAME)
        return clf
    except Exception as e:
        st.error("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ‡ÐµÑ€ÐµÐ· pipeline. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸.")
        st.write(e)
        return None

def text_heuristics(text: str):
    """Return simple heuristic scores in 0..1 for manipulative language."""
    if not text:
        return {
            "sensational_ratio": 0.0,
            "caps_ratio": 0.0,
            "exclaim_ratio": 0.0,
            "length_norm": 0.0
        }
    txt_lower = text.lower()
    words = text.split()
    n_words = max(len(words), 1)


    sensational_count = sum(1 for w in SENSATIONAL_WORDS if w in txt_lower)
    sensational_ratio = min(1.0, sensational_count / 3.0)


    caps_words = sum(1 for w in words if sum(1 for c in w if c.isupper()) > 0 and (sum(1 for c in w if c.isupper())/max(len(w),1) > 0.6))
    caps_ratio = min(1.0, caps_words / max(1, n_words))


    exclaim_count = text.count("!")
    exclaim_ratio = min(1.0, exclaim_count / 3.0)


    length_norm = 1.0 - min(1.0, math.log(n_words + 1) / math.log(200 + 1)) 

    return {
        "sensational_ratio": sensational_ratio,
        "caps_ratio": caps_ratio,
        "exclaim_ratio": exclaim_ratio,
        "length_norm": length_norm
    }

def compute_text_score(heur: dict):
    

    score = (0.4 * heur["sensational_ratio"] +
             0.25 * heur["caps_ratio"] +
             0.2 * heur["exclaim_ratio"] +
             0.15 * heur["length_norm"])
    return min(1.0, max(0.0, score))

def compute_trust_score(model_label: str, model_score: float, text_manip_score: float, media_flag: float):
   

    if model_label.upper() == "FAKE":
        model_trust = 1 - model_score
    else:
        model_trust = model_score

    
    text_trust = 1 - text_manip_score

    
    media_trust = 1 - media_flag

    combined = W_MODEL * model_trust + W_TEXTHEUR * text_trust + W_MEDIA * media_trust
    trust_percent = int(round(100 * combined))
    trust_percent = max(0, min(100, trust_percent))
    return trust_percent

def ensure_dirs():
    os.makedirs(REPORTS_DIR, exist_ok=True)
    os.makedirs(IMAGE_DB_DIR, exist_ok=True)

def save_report(report: dict):
    ensure_dirs()
    ts = int(time.time())
    fname = os.path.join(REPORTS_DIR, f"report_{ts}.json")
    with open(fname, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    return fname

def image_similarity_hash(pil_img: Image.Image):
    """Compute perceptual hash (pHash) for the image and compare with IMAGE_DB_DIR files."""
    h = imagehash.phash(pil_img)
    similar = []
    if not os.path.exists(IMAGE_DB_DIR):
        return {"hash": str(h), "matches": []}
    for fn in os.listdir(IMAGE_DB_DIR):
        fp = os.path.join(IMAGE_DB_DIR, fn)
        try:
            db_img = Image.open(fp)
            db_h = imagehash.phash(db_img)
            dist = h - db_h 
            if dist <= 8:
                similar.append({"file": fn, "distance": int(dist)})
        except Exception:
            continue
    return {"hash": str(h), "matches": similar}


def main():
    st.set_page_config(page_title="MVP Fake & Deepfake Detector", page_icon="ðŸ•µï¸â€â™€ï¸", layout="centered")
    st.title(" Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ñ„ÐµÐ¹ÐºÐ¾Ð²Ñ‹Ñ… Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ ")



    
    col1, col2 = st.columns([3,1])

    with col1:
        
        mode = st.radio("Ð ÐµÐ¶Ð¸Ð¼ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸", ["Ð¢ÐµÐºÑÑ‚", "Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", "ÐžÐ±Ð°"], index=0)

        user_text = ""
        uploaded_image = None

        if mode in ("Ð¢ÐµÐºÑÑ‚", "ÐžÐ±Ð°"):
            user_text = st.text_area("Ð’ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº", height=200)
        if mode in ("Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", "ÐžÐ±Ð°"):
            uploaded_file = st.file_uploader("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (jpg/png)", type=["jpg","jpeg","png"])
            if uploaded_file is not None:
                uploaded_image = Image.open(io.BytesIO(uploaded_file.read()))
                st.image(uploaded_image, caption="Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ")

        run = st.button("ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ")

    

    if run:
        ensure_dirs()
        t0 = time.time()
        
        with st.spinner("Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (ÐµÑÐ»Ð¸ ÐµÑ‰Ñ‘ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°)..."):
            clf = load_model()
        
        if clf is None:
            st.error("ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ (assume REAL Ñ Ð½Ð¸Ð·ÐºÐ¾Ð¹ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒÑŽ).")
            model_label = "REAL"
            model_conf = 0.6
        else:
            if mode in ("Ð¢ÐµÐºÑÑ‚", "ÐžÐ±Ð°") and user_text.strip():
                with st.spinner("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚..."):
                    try:
                        res = clf(user_text[:1000])  
                        if isinstance(res, list):
                            r0 = res[0]
                        else:
                            r0 = res
                        model_label = r0.get("label", "REAL")
                        model_conf = float(r0.get("score", 0.5))
                    except Exception as e:
                        st.write("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:", e)
                        model_label = "REAL"
                        model_conf = 0.5
            else:
                
                model_label = "REAL"
                model_conf = 0.5

        
        heur = text_heuristics(user_text)
        text_manip_score = compute_text_score(heur)

        
        media_flag = 0.0
        image_info = None
        if uploaded_image is not None:
            with st.spinner("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (pHash ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ)..."):
                image_info = image_similarity_hash(uploaded_image)
                matches = image_info.get("matches", [])
                if matches:
                    
                    media_flag = min(1.0, 0.6 + 0.1 * len(matches))
                else:
                    media_flag = 0.0

        trust = compute_trust_score(model_label, model_conf, text_manip_score, media_flag)

        
        st.header("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")
        st.subheader(f"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° Ð´Ð¾Ð²ÐµÑ€Ð¸Ñ: {trust}%")
        st.progress(trust / 100)

        st.markdown("### ÐœÐ¾Ð´ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° (NLP)")

# ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¼ÐµÑ‚Ð¾Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸
        label_map = {
            "NEGATIVE": "Ð›Ð¾Ð¶Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ",
            "FAKE": "Ð›Ð¾Ð¶Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ",
            "POSITIVE": "Ð”Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾",
            "REAL": "Ð”Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾",
            "Fake": "Ð›Ð¾Ð¶Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ",
            "Real": "Ð”Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾"
        }
        user_friendly_label = label_map.get(model_label, model_label)

        st.write(f"- ÐœÐµÑ‚ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸: **{user_friendly_label}**")
        st.write(f"- Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸: **{model_conf:.2f}**")


        st.markdown("### Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¼Ð°Ð½Ð¸Ð¿ÑƒÐ»ÑÑ†Ð¸Ð¸ (ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ¸)")
        st.write(f"- Ð¡ÐµÐ½ÑÐ°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° (fraction): **{heur['sensational_ratio']:.2f}**")
        st.write(f"- Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ CAPS-ÑÐ»Ð¾Ð²: **{heur['caps_ratio']:.2f}**")
        st.write(f"- Ð’Ð¾ÑÐºÐ»Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð½Ð°ÐºÐ¸: **{heur['exclaim_ratio']:.2f}**")
        st.write(f"- ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ÑÑ‚ÑŒ/Headline Ñ„Ð°ÐºÑ‚Ð¾Ñ€: **{heur['length_norm']:.2f}**")
        st.write(f"- Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¼Ð°Ð½Ð¸Ð¿ÑƒÐ»ÑÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÑÐºÐ¾Ñ€: **{text_manip_score:.2f}**")

        st.markdown("### ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (pHash)")
        if image_info is not None:
            st.write(f"- pHash Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: `{image_info.get('hash')}`")
            if image_info.get("matches"):
                st.write("- ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² local image_db (Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð°Ñ Ð¿ÐµÑ€ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ°):")
                for m in image_info["matches"]:
                    st.write(f"  - {m['file']} (hamming distance = {m['distance']})")
                st.warning("ÐÐ°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐ°ÑŽÑ‚ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ")
            else:
                st.write("- Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð±Ð°Ð·Ðµ (image_db).")
        else:
            st.write("- Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾.")

        
        
        for r in reasons:
            st.write("- " + r)

        
        report = {
            "timestamp": int(t0),
            "input_text": user_text,
            "model_label": model_label,
            "model_confidence": model_conf,
            "heuristics": heur,
            "text_manip_score": text_manip_score,
            "image_info": image_info,
            "media_flag": media_flag,
            "trust": trust
        }
        saved = save_report(report)
        st.caption(f"ÐžÑ‚Ñ‡Ñ‘Ñ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {saved}")

        st.success(f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ â€” Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½ Ð·Ð° {int(time.time()-t0)} ÑÐµÐº.")

    
    st.markdown("---")
if __name__ == "__main__":
    main()

